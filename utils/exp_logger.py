# coding : utf-8
# Author : yuxiang Zeng

import os
import platform
import shutil
import time
import logging
import pickle
import numpy as np
import torch
from exp.exp_efficiency import *
from torch.utils.tensorboard import SummaryWriter


class Logger:
    def __init__(self, filename, exper_detail, plotter, config, show_params=True):
        self.filename = filename
        self.exper_detail = exper_detail
        self.plotter = plotter
        self.config = config
        self._init_log_file()
        if config.hyper_search:
            self.exper_filename += "_hyper_search"
        # è®¾ç½®æ—¥å¿—è®°å½•åˆ°æ–‡ä»¶
        logging.basicConfig(
            level=logging.INFO,
            filename=f"{self.exper_filename}.md",
            filemode="w",
            format="%(message)s",
        )
        self.logger = logging.getLogger(config.model)
        config.log = self
        self._prepare_experiment(show_params)

        # åˆ›å»ºtensorboard
        self.base_log_dir = os.path.join("./runs", config.model, self.filename)
        self.tb_writer = None  # å…ˆå ä¸ªä½ï¼Œä¸åœ¨ init é‡Œåˆ›å»º

    # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶è·¯å¾„
    def _init_log_file(self):
        fileroot = f"./results/{self.config.model}/" + time.strftime("%Y%m%d") + "/log/"
        os.makedirs(fileroot, exist_ok=True)
        timestamp = time.strftime("%H_%M_%S")
        self.exper_filename = os.path.join(fileroot, f"{timestamp}_{self.filename}")

    # æ‰“å°åˆå§‹é…ç½®å‚æ•°
    def _prepare_experiment(self, show_params):
        self.logger.info("```python")
        if show_params:
            self.log(self._format_config_dict(self.config.__dict__))

    # ä¿å­˜è¿è¡Œæ—¥å¿—åˆ°run.logæ–‡ä»¶
    def save_in_log(self, metrics):
        # === è·å– CPU åç§° ===
        cpu_name = platform.processor()
        if not cpu_name:
            cpu_name = platform.machine()
        device_name = f"CPU-{cpu_name}"

        # === å¦‚æœæœ‰ GPUï¼Œæ·»åŠ  GPU åç§° ===
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            device_name += f"_GPU-{gpu_name}"

        # === æ¸…ç†éæ³•å­—ç¬¦ï¼Œç”Ÿæˆæ–‡ä»¶å tag ===
        device_tag = (
            device_name.replace(" ", "-")
            .replace("/", "-")
            .replace("(", "")
            .replace(")", "")
        )

        # === æ„é€ æ—¥å¿—æ–‡ä»¶è·¯å¾„ ===
        log_path = f"./{device_tag}_{self.config.logger}"

        with open(f"./{log_path}.log", "a") as f:
            timestamp = time.strftime("|%Y-%m-%d %H:%M:%S| ")
            f.write(timestamp + self.exper_detail + "\n")
            metric_str = " ".join(
                [f"{k} - {np.mean(v):.4f}" for k, v in metrics.items()]
            )
            f.write(timestamp + metric_str + "\n")

    # ä¿å­˜ç»“æœåˆ°pickleæ–‡ä»¶
    def save_result(self, metrics):
        os.makedirs("./results/metrics/", exist_ok=True)
        config_copy = {k: v for k, v in self.config.__dict__.items() if k != "log"}
        result = {
            "config": config_copy,
            "dataset": self.config.model,
            "model": self.config.model,
            **{k: metrics[k] for k in metrics},
            **{f"{k}_mean": np.mean(metrics[k]) for k in metrics},
            **{f"{k}_std": np.std(metrics[k]) for k in metrics},
        }
        with open(f"./results/metrics/{self.filename}.pkl", "wb") as f:
            pickle.dump(result, f)

    # æ—¥å¿—è¾“å‡ºï¼ˆå«å½©è‰²æ‰“å°ï¼‰
    def log(self, string):
        if string.startswith("\n"):
            string = string[1:]
            print("\n", end="")
            self.logger.info("")
        timestamp = time.strftime("|%Y-%m-%d %H:%M:%S| ")
        self.logger.info(timestamp + string)
        self.only_print(string)

    def __call__(self, string):
        self.log(string)

    # ç»ˆç«¯å½©è‰²è¾“å‡ºè¾…åŠ©å‡½æ•°
    def only_print(self, string):
        timestamp = time.strftime("|%Y-%m-%d %H:%M:%S| ")
        print(f"\033[1;38;2;151;200;129m{timestamp}\033[0m\033[1m{string}\033[0m")

    # å±•ç¤ºä¸€æ¬¡å®Œæ•´å®éªŒç»“æœ
    def show_results(self, results, sum_time):
        monitor = self.config.monitor_metric
        summary = f"Valid{monitor}={-results[monitor]:.4f} ï½œ "
        summary += " ".join([f"{k}={v:.4f}" for k, v in results.items()])
        summary += f" time={sum_time:.1f} s"
        self.only_print(summary)

    # å±•ç¤ºè®­ç»ƒä¸­çš„æŸè½® epoch çš„è¯¯å·®
    def show_epoch_error(self, runid, epoch, monitor, epoch_loss, results, train_time):
        if self.config.verbose and epoch % self.config.verbose == 0 and epoch > 0:
            self.only_print(self.exper_detail)
            best = f"Best Epoch {monitor.best_epoch} {self.config.monitor_metric} = {-monitor.best_score:.4f}  now = {epoch - monitor.best_epoch}"
            self.only_print(best)
            summary = f"Round={runid + 1} Epoch={epoch + 1:03d} Loss={epoch_loss:.4f} "
            summary += " ".join([f"v{k}={v:.4f}" for k, v in results.items()])
            summary += f" time={sum(train_time):.1f} s"
            self.only_print(summary)
        self.log_tensorboard(epoch, epoch_loss, results, train_time)

    # å±•ç¤ºæœ€ç»ˆæµ‹è¯•ç»“æœ
    def show_test_error(self, runid, monitor, results, sum_time):
        summary = f"Round={runid + 1} BestEpoch={monitor.best_epoch:3d} "
        summary += f"Valid{self.config.monitor_metric}={-monitor.best_score:.4f} ï½œ "
        summary += " ".join([f"{k}={v:.4f}" for k, v in results.items()])
        summary += f" time={sum_time:.1f} s"
        self.log(summary)

        # === 2. TensorBoard æ¨ªå‘ Markdown è¡¨æ ¼ (ä¿®æ”¹ç‰ˆ) ===
        if self.tb_writer:
            # --- ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡åˆ—è¡¨ ---
            # 1. æ ¸å¿ƒæŒ‡æ ‡
            headers = ["Best Epoch", f"Valid {self.config.monitor_metric}"]
            values = [f"`{monitor.best_epoch}`", f"`{-monitor.best_score:.4f}`"]

            # 2. å¾ªç¯æ·»åŠ å…¶ä»–æ‰€æœ‰æŒ‡æ ‡
            for k, v in results.items():
                headers.append(k)  # è¡¨å¤´
                values.append(f"`{v:.4f}`")  # æ•°å€¼(åŠ åå¼•å·é«˜äº®)

            # 3. æ·»åŠ æ—¶é—´
            headers.append("Total Time")
            values.append(f"`{sum_time:.1f} s`")

            # --- ç¬¬äºŒæ­¥ï¼šæ‹¼æ¥ Markdown ---
            # æ ‡é¢˜
            md_table = f"### ğŸ† Round {runid + 1} Test Summary\n\n"

            # æ‹¼è¡¨å¤´: | Best Epoch | Valid RMSE | MAE | ... |
            md_table += "| " + " | ".join(headers) + " |\n"

            # æ‹¼åˆ†å‰²çº¿: | :--- | :--- | :--- | ... | (æ ¹æ®åˆ—æ•°è‡ªåŠ¨ç”Ÿæˆ)
            md_table += "| " + " | ".join([":---"] * len(headers)) + " |\n"

            # æ‹¼æ•°å€¼è¡Œ: | 123 | 0.8321 | 2.14 | ... |
            md_table += "| " + " | ".join(values) + " |\n"

            # --- ç¬¬ä¸‰æ­¥ï¼šå†™å…¥ ---
            self.tb_writer.add_text("Summary/Test_Results", md_table, 0)
            self.tb_writer.flush()  # å¼ºåˆ¶å†™å…¥ç¡¬ç›˜

    # é…ç½®å‚æ•°æ ¼å¼åŒ–è¾“å‡º
    def _format_config_dict(self, config_dict, items_per_line=3):
        sorted_items = sorted(config_dict.items())
        lines = [
            ", ".join([f"'{k}': {v}" for k, v in sorted_items[i : i + items_per_line]])
            for i in range(0, len(sorted_items), items_per_line)
        ]
        return "{\n" + "\n".join(["     " + line for line in lines]) + "\n}"

    # åˆ é™¤ç©ºæ–‡ä»¶å¤¹
    def _delete_empty_directories(self, dir_path):
        # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
        if os.path.exists(dir_path) and os.path.isdir(dir_path):
            # éå†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•ï¼Œä»æœ€åº•å±‚å¼€å§‹
            for root, dirs, files in os.walk(dir_path, topdown=False):
                # å…ˆåˆ é™¤ç©ºçš„å­ç›®å½•
                for name in dirs:
                    dir_to_remove = os.path.join(root, name)
                    # å¦‚æœç›®å½•æ˜¯ç©ºçš„ï¼Œåˆ™åˆ é™¤å®ƒ
                    try:
                        if not os.listdir(dir_to_remove):  # åˆ¤æ–­ç›®å½•æ˜¯å¦ä¸ºç©º
                            os.rmdir(dir_to_remove)
                            print(f"Directory {dir_to_remove} has been deleted.")
                    except FileNotFoundError:
                        # å¦‚æœç›®å½•å·²ç»ä¸å­˜åœ¨ï¼Œå¿½ç•¥æ­¤é”™è¯¯
                        pass
                # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦ä¹Ÿæ˜¯ç©ºçš„ï¼Œå¦‚æœæ˜¯åˆ™åˆ é™¤å®ƒ
                try:
                    if not os.listdir(root):  # åˆ¤æ–­å½“å‰æ ¹ç›®å½•æ˜¯å¦ä¸ºç©º
                        os.rmdir(root)
                        print(f"Directory {root} has been deleted.")
                except FileNotFoundError:
                    # å¦‚æœç›®å½•å·²ç»ä¸å­˜åœ¨ï¼Œå¿½ç•¥æ­¤é”™è¯¯
                    pass
        else:
            print(f"Directory {dir_path} does not exist.")

    # å®éªŒç»“æŸæ—¶æ‰§è¡Œçš„æ¸…ç†æ“ä½œ
    def end_the_experiment(self, model):
        self.logger.info(f"\n{str(model)}")
        self.logger.info("```")
        self._delete_empty_directories("./results/")

    ###############
    def set_runid(self, runid):
        # 1. ä¹‹å‰å¦‚æœæœ‰ writerï¼Œå…ˆå…³æ‰
        if self.tb_writer is not None:
            self.tb_writer.close()

        # 2. ç¡®å®šæ–‡ä»¶å¤¹è·¯å¾„
        log_dir = os.path.join(self.base_log_dir, f"Round_{runid}")

        # === [æ–°å¢] å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œç›´æ¥åˆ é™¤ï¼Œé˜²æ­¢æ—§æ•°æ®å¹²æ‰° ===
        if os.path.exists(log_dir):
            try:
                shutil.rmtree(log_dir)  # é€’å½’åˆ é™¤æ–‡ä»¶å¤¹
                print(f"Cleaned up old logs in: {log_dir}")
            except OSError as e:
                print(f"Error: {log_dir} : {e.strerror}")
        # ======================================================

        # 3. é‡æ–°åˆ›å»ºå…¨æ–°çš„æ–‡ä»¶å¤¹å’Œ writer
        self.tb_writer = SummaryWriter(log_dir=log_dir)

        return True

    # === 1. è®°å½•è¶…å‚æ•° (Hyperparameters) ===
    # è¿™æ ·ä½ å¯ä»¥åœ¨ TensorBoard çš„ "HPARAMS" æ ç›®é‡Œç­›é€‰å‡ºæœ€å¥½çš„å‚æ•°ç»„åˆ
    def log_hparams(self, config, metrics):
        # è¿‡æ»¤æ‰ config ä¸­æ— æ³•åºåˆ—åŒ–çš„å¯¹è±¡ï¼Œåªç•™ int, float, str, bool
        hparam_dict = {
            k: v
            for k, v in config.__dict__.items()
            if isinstance(v, (int, float, str, bool))
        }

        # ä½ çš„ metrics å¯èƒ½æ˜¯ listï¼Œè¿™é‡Œå–å‡å€¼ä½œä¸ºæœ€ç»ˆæŒ‡æ ‡
        metric_dict = {k: np.mean(v) for k, v in metrics.items()}

        if self.tb_writer:
            self.tb_writer.add_hparams(hparam_dict, metric_dict)

    # === 2. è®°å½•æ¨¡å‹ç»“æ„ (ä¿®å¤ç‰ˆ) ===
    def log_model_graph(self, model, datamodule, device):
        if self.tb_writer:
            try:
                # 1. æ‹¿ä¸€ä¸ª batch çš„æ•°æ®
                batch = next(iter(datamodule.train_loader))

                # 2. é¢„å¤„ç†æ•°æ®
                # å‡è®¾ batch æ˜¯ä¸€ä¸ª list: [feat, eig, in, out, dij, label]
                # æˆ‘ä»¬éœ€è¦æŠŠå®ƒä»¬éƒ½æŒªåˆ° device ä¸Š
                if isinstance(batch, (list, tuple)):
                    batch = [x.to(device) for x in batch]

                    # ã€å…³é”®ç‚¹ã€‘
                    # é€šå¸¸ batch çš„æœ€åä¸€ä¸ªå…ƒç´ æ˜¯ label/targetï¼Œæ¨¡å‹ forward ä¸éœ€è¦å®ƒ
                    # å¦‚æœä½ çš„ forward åˆšå¥½éœ€è¦ batch é‡Œé™¤æœ€åä¸€ä¸ªä»¥å¤–çš„æ‰€æœ‰å…ƒç´ ï¼š
                    inputs_to_model = tuple(batch[:-1])

                    # âš ï¸å¦‚æœæ¨¡å‹éœ€è¦ batch é‡Œæ‰€æœ‰çš„å…ƒç´ ï¼ˆæ²¡æœ‰å•ç‹¬çš„ labelï¼‰ï¼Œå°±ç”¨ä¸‹é¢è¿™è¡Œï¼š
                    # inputs_to_model = tuple(batch)
                else:
                    # å¦‚æœ batch æœ¬èº«å°±æ˜¯å•ä¸ª tensor
                    inputs_to_model = batch.to(device)

                # 3. ä¼ å…¥ Tupleï¼Œadd_graph ä¼šè‡ªåŠ¨è§£åŒ…æˆå¤šä¸ªå‚æ•°ä¼ ç»™ forward
                self.tb_writer.add_graph(model, input_to_model=inputs_to_model)
                print("Success: Model graph added to TensorBoard.")

            except Exception as e:
                # å¦‚æœè¿˜æ˜¯æŠ¥é”™ï¼Œæ‰“å°å‡ºæ¥æ–¹ä¾¿è°ƒè¯•ï¼Œä¸å¡æ­»ç¨‹åº
                print(f"Warning: Failed to add model graph to TensorBoard. Error: {e}")

    # === 3. è®°å½•æƒé‡å’Œæ¢¯åº¦ç›´æ–¹å›¾ (Histograms) ===
    # ç”¨äºæ£€æŸ¥æ¢¯åº¦æ¶ˆå¤±/çˆ†ç‚¸ï¼Œæˆ–è€…æƒé‡æ˜¯å¦æ›´æ–°
    def log_histograms(self, model, epoch):
        if self.tb_writer:
            for name, param in model.named_parameters():
                if param.requires_grad:
                    # è®°å½•æƒé‡å€¼åˆ†å¸ƒ
                    self.tb_writer.add_histogram(f"Weights/{name}", param, epoch)
                    # è®°å½•æ¢¯åº¦å€¼åˆ†å¸ƒ (åªæœ‰åœ¨ backward ä¹‹åæ‰æœ‰å€¼)
                    if param.grad is not None:
                        self.tb_writer.add_histogram(
                            f"Gradients/{name}", param.grad, epoch
                        )

    # === 4. è®°å½•é…ç½®æ–‡æœ¬ (Markdown è¡¨æ ¼ç‰ˆï¼šæ¯è¡Œ 5 ä¸ª) ===
    def log_config_text(self, config):
        if self.tb_writer:
            # 1. å‡†å¤‡æ•°æ®
            # æ ¼å¼åŒ–ä¸º "**Key**: `Value`" çš„å½¢å¼
            # è¿‡æ»¤æ‰ä»¥ '_' å¼€å¤´çš„ç§æœ‰å±æ€§ï¼ˆå¯é€‰ï¼‰
            params = [
                f"**{k}**: `{v}`"
                for k, v in sorted(config.__dict__.items())
                if not k.startswith("_")
            ]

            # 2. æ ¸å¿ƒé€»è¾‘ï¼šæ¯ 5 ä¸ªå‚æ•°ä¸€è¡Œ
            COLUMNS = 5

            # æ„å»ºè¡¨å¤´ | P1 | P2 | P3 | P4 | P5 |
            headers = [f"Param {i+1}" for i in range(COLUMNS)]
            md_table = "### Experiment Configuration\n\n"
            md_table += "| " + " | ".join(headers) + " |\n"
            md_table += "| " + " | ".join([":---"] * COLUMNS) + " |\n"  # å·¦å¯¹é½

            # 3. å¡«å……æ•°æ®è¡Œ
            for i in range(0, len(params), COLUMNS):
                # å–å‡ºå½“å‰è¡Œçš„åˆ‡ç‰‡
                row_items = params[i : i + COLUMNS]

                # å¦‚æœä¸è¶³ 5 ä¸ªï¼Œç”¨ç©ºå­—ç¬¦ä¸²è¡¥é½ï¼Œå¦åˆ™ Markdown è¡¨æ ¼ä¼šä¹±
                if len(row_items) < COLUMNS:
                    row_items += [""] * (COLUMNS - len(row_items))

                # æ‹¼æ¥è¿™ä¸€è¡Œ
                md_table += "| " + " | ".join(row_items) + " |\n"

            # 4. å†™å…¥
            self.tb_writer.add_text("Config_Details", md_table, 0)
            self.tb_writer.flush()

    # === 5. (å¯é€‰) è®°å½• Embedding æŠ•å½± ===
    # å¦‚æœä½ çš„æ¨¡å‹æœ‰ Encoder è¾“å‡ºç‰¹å¾ï¼Œæƒ³çœ‹è¿™äº›ç‰¹å¾åœ¨ç©ºé—´é‡Œæ€ä¹ˆèšç±»çš„
    def log_embeddings(self, features, labels, epoch):
        if self.tb_writer:
            # features: [N, D_model], labels: [N] (ç”¨äºç€è‰²)
            self.tb_writer.add_embedding(features, metadata=labels, global_step=epoch)

    # [æ–°å¢] ä¸“é—¨ç”¨äºå†™ TensorBoard çš„å‡½æ•°
    def log_tensorboard(self, epoch, train_loss, results, train_time):
        if self.tb_writer:
            # 1. è®°å½• Loss
            self.tb_writer.add_scalar(
                f"Metrics/{self.config.loss_func}", train_loss, epoch
            )
            # 2. è®°å½•æ‰€æœ‰éªŒè¯æŒ‡æ ‡ (results æ˜¯ä¸€ä¸ªå­—å…¸)
            for key, value in results.items():
                self.tb_writer.add_scalar(f"Metrics/{key}", value, epoch)

    # å®éªŒç»“æŸåè®°å¾—å…³é—­
    def close(self):
        self.tb_writer.close()
