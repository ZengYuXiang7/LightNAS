{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c92a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "./checkpoints/brp-nas/Modelbrp-nas_datasetnasbench201_dstdatasetdesktop-cpu-core-i7-7820x-fp32_spliterratio5:4:91_dmodel64_round_0.pt\n",
    "./checkpoints/brp-nas/Modelbrp-nas_datasetnasbench201_dstdatasetdesktop-cpu-core-i7-7820x-fp32_spliterratio5:4:91_dmodel64_round_0.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9750a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_ops                                                    | Shape: torch.Size([1])               \n",
      "total_params                                                 | Shape: torch.Size([1])               \n",
      "model.total_ops                                              | Shape: torch.Size([1])               \n",
      "model.total_params                                           | Shape: torch.Size([1])               \n",
      "model.GCN.total_ops                                          | Shape: torch.Size([1])               \n",
      "model.GCN.total_params                                       | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.total_ops                                      | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.total_params                                   | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.0.weight                                       | Shape: torch.Size([6, 600])          \n",
      "model.GCN.gcn.0.bias                                         | Shape: torch.Size([600])             \n",
      "model.GCN.gcn.0.total_ops                                    | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.0.total_params                                 | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.1.weight                                       | Shape: torch.Size([600, 600])        \n",
      "model.GCN.gcn.1.bias                                         | Shape: torch.Size([600])             \n",
      "model.GCN.gcn.1.total_ops                                    | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.1.total_params                                 | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.2.weight                                       | Shape: torch.Size([600, 600])        \n",
      "model.GCN.gcn.2.bias                                         | Shape: torch.Size([600])             \n",
      "model.GCN.gcn.2.total_ops                                    | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.2.total_params                                 | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.3.weight                                       | Shape: torch.Size([600, 600])        \n",
      "model.GCN.gcn.3.bias                                         | Shape: torch.Size([600])             \n",
      "model.GCN.gcn.3.total_ops                                    | Shape: torch.Size([1])               \n",
      "model.GCN.gcn.3.total_params                                 | Shape: torch.Size([1])               \n",
      "model.GCN.norm.total_ops                                     | Shape: torch.Size([1])               \n",
      "model.GCN.norm.total_params                                  | Shape: torch.Size([1])               \n",
      "model.GCN.norm.0.weight                                      | Shape: torch.Size([600])             \n",
      "model.GCN.norm.0.bias                                        | Shape: torch.Size([600])             \n",
      "model.GCN.norm.1.weight                                      | Shape: torch.Size([600])             \n",
      "model.GCN.norm.1.bias                                        | Shape: torch.Size([600])             \n",
      "model.GCN.norm.2.weight                                      | Shape: torch.Size([600])             \n",
      "model.GCN.norm.2.bias                                        | Shape: torch.Size([600])             \n",
      "model.GCN.norm.3.weight                                      | Shape: torch.Size([600])             \n",
      "model.GCN.norm.3.bias                                        | Shape: torch.Size([600])             \n",
      "model.GCN.act.total_ops                                      | Shape: torch.Size([1])               \n",
      "model.GCN.act.total_params                                   | Shape: torch.Size([1])               \n",
      "model.GCN.dropout.total_ops                                  | Shape: torch.Size([1])               \n",
      "model.GCN.dropout.total_params                               | Shape: torch.Size([1])               \n",
      "model.GCN.fc.weight                                          | Shape: torch.Size([1, 600])          \n",
      "model.GCN.fc.bias                                            | Shape: torch.Size([1])               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1076052/2332740234.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 设置模型文件路径\n",
    "model_path = './checkpoints/brp-nas/Modelbrp-nas_datasetnasbench201_dstdatasetdesktop-cpu-core-i7-7820x-fp32_spliterratio5:4:91_dmodel64_round_0.pt'\n",
    "\n",
    "# 加载模型的权重\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# 逐层打印每个权重的形状\n",
    "for name, param in state_dict.items():\n",
    "    print(f\"{name.ljust(60)} | Shape: {str(param.shape).ljust(30)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_rank = lossRank(logits, gt) * config.lambda_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1aaf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_pre, auged_pre = torch.split(pre, pre.shape[0]//2, dim=0)\n",
    "                loss_con = lossConsistency(source_pre, auged_pre) * config.lambda_consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossRank = DiffLoss(args.rankloss_type)\n",
    "    lossConsistency = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08049b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "class CalPairDiff(nn.Module):\n",
    "    def __init__(self, type):\n",
    "        super(CalPairDiff, self).__init__()\n",
    "        if type.lower() == 'l1':\n",
    "            self.cal_loss = nn.L1Loss()\n",
    "        elif type.lower() == 'l2':\n",
    "            self.cal_loss = nn.MSELoss()\n",
    "        elif type.lower() == 'kldiv':\n",
    "            self.cal_loss = nn.KLDivLoss()\n",
    "        \n",
    "    def forward(self, predicts, target):\n",
    "        B = predicts.shape[0]\n",
    "        ori_pre = predicts\n",
    "        ori_tar = target\n",
    "        index = list(range(B))\n",
    "        random.shuffle(index)\n",
    "        predicts = predicts[index]\n",
    "        target = target[index]\n",
    "        v1 = ori_pre - predicts\n",
    "        v2 = ori_tar - target\n",
    "        loss = self.cal_loss(v1, v2)\n",
    "        return loss\n",
    "\n",
    "class DiffLoss(nn.Module):\n",
    "    def __init__(self, type):\n",
    "        super(DiffLoss, self).__init__()\n",
    "        self.crit = CalPairDiff(type)\n",
    "\n",
    "    def forward(self, predicts, target):\n",
    "        loss = self.crit(predicts, target)\n",
    "        return loss\n",
    "\n",
    "loss = DiffLoss('l1')\n",
    "a1=torch.tensor([0, 2, 4, 6, 8, 10, 12, 14, 16, 18], dtype=float)\n",
    "a2=torch.tensor([1, 3, 5, 7, 9, 11, 13, 15, 17, 19], dtype=float)\n",
    "l1 = loss(a1, a2)\n",
    "\n",
    "b1=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=float)\n",
    "b2=torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=float)\n",
    "l2 = loss(b1, b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e1c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
